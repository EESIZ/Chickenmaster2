"""Citation Tracer - ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì€ ì¸ìš© ê·¸ëž˜í”„ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤:
- JSON í˜•ì‹: ê¸°ê³„ ê°€ë…ì„±, í›„ì²˜ë¦¬ ìš©ì´
- Markdown í˜•ì‹: ì‚¬ëžŒì´ ì½ê¸° ì‰¬ìš´ ë¦¬í¬íŠ¸, ì‹œê°í™” í¬í•¨

Example:
    >>> from citation_tracer.reporter import generate_markdown_report
    >>> from citation_tracer.graph import CitationGraph
    >>> 
    >>> graph = CitationGraph()
    >>> # ... ê·¸ëž˜í”„ êµ¬ì„± ...
    >>> generate_markdown_report(graph, seed_info, "lineage_report.md")

Author: citation-tracer agent
Created: 2026-01-15
"""

from __future__ import annotations

import json
import logging
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Protocol, Sequence, Union

logger = logging.getLogger(__name__)


# =============================================================================
# íƒ€ìž… ì •ì˜ (Protocolì„ ì‚¬ìš©í•œ ë• íƒ€ì´í•‘)
# =============================================================================


class PaperLike(Protocol):
    """ë…¼ë¬¸ ì •ë³´ í”„ë¡œí† ì½œ.
    
    CitationGraphì˜ ë…¸ë“œì—ì„œ ë…¼ë¬¸ ì •ë³´ë¥¼ ì¶”ì¶œí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    paper_id: str
    title: str
    authors: List[str]
    year: Optional[int]
    citation_count: int
    influential_citation_count: int
    abstract: str
    external_ids: Dict[str, str]


class CitationNodeLike(Protocol):
    """ì¸ìš© ë…¸ë“œ í”„ë¡œí† ì½œ.
    
    CitationGraphì˜ ë…¸ë“œ íƒ€ìž… ížŒíŠ¸ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    canonical_id: str
    paper: PaperLike
    depth: int
    relevance_score: float
    is_foundation: bool


class CitationEdgeLike(Protocol):
    """ì¸ìš© ì—£ì§€ í”„ë¡œí† ì½œ.
    
    CitationGraphì˜ ì—£ì§€ íƒ€ìž… ížŒíŠ¸ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    
    source_id: str
    target_id: str
    edge_type: str


class CitationGraphLike(Protocol):
    """ì¸ìš© ê·¸ëž˜í”„ í”„ë¡œí† ì½œ.
    
    ë¦¬í¬í„° í•¨ìˆ˜ì—ì„œ ë°›ëŠ” ê·¸ëž˜í”„ ê°ì²´ì˜ ìµœì†Œ ì¸í„°íŽ˜ì´ìŠ¤ìž…ë‹ˆë‹¤.
    """
    
    nodes: Dict[str, CitationNodeLike]
    edges: List[CitationEdgeLike]
    
    def get_foundation_candidates(self, min_depth: int = 2) -> List[CitationNodeLike]:
        """Foundation candidate ë…¸ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        ...
    
    def to_dict(self) -> Dict[str, Any]:
        """ê·¸ëž˜í”„ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì§ë ¬í™”í•©ë‹ˆë‹¤."""
        ...


# =============================================================================
# JSON ë¦¬í¬íŠ¸ ìƒì„±
# =============================================================================


def generate_json_report(
    graph: CitationGraphLike,
    output_path: Union[str, Path],
    *,
    indent: int = 2,
    include_abstracts: bool = False,
    metadata: Optional[Dict[str, Any]] = None,
) -> Path:
    """ì¸ìš© ê·¸ëž˜í”„ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.
    
    ê·¸ëž˜í”„ êµ¬ì¡°ë¥¼ JSON íŒŒì¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ìž¥í•©ë‹ˆë‹¤.
    í›„ì† ë¶„ì„ì´ë‚˜ ì‹œê°í™” ë„êµ¬ì—ì„œ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
    
    Args:
        graph: ì €ìž¥í•  ì¸ìš© ê·¸ëž˜í”„ ê°ì²´.
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ë¬¸ìžì—´ ë˜ëŠ” Path ê°ì²´).
        indent: JSON ë“¤ì—¬ì“°ê¸° í¬ê¸° (ê¸°ë³¸ê°’: 2).
        include_abstracts: ì´ˆë¡ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: False, íŒŒì¼ í¬ê¸° ì ˆê°).
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (ì„ íƒ).
    
    Returns:
        ì €ìž¥ëœ íŒŒì¼ì˜ Path ê°ì²´.
    
    Raises:
        OSError: íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨ ì‹œ.
        TypeError: ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ë°ì´í„° í¬í•¨ ì‹œ.
    
    Example:
        >>> graph = CitationGraph()
        >>> # ... ê·¸ëž˜í”„ êµ¬ì„± ...
        >>> path = generate_json_report(graph, "results/lineage.json")
        >>> print(f"ì €ìž¥ ì™„ë£Œ: {path}")
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ê¸°ë³¸ ê·¸ëž˜í”„ ë°ì´í„°
    data = graph.to_dict()
    
    # ìƒì„¸ ë…¸ë“œ ì •ë³´ ì¶”ê°€
    detailed_nodes: List[Dict[str, Any]] = []
    for node in graph.nodes.values():
        node_data: Dict[str, Any] = {
            "canonical_id": node.canonical_id,
            "paper_id": node.paper.paper_id,
            "title": node.paper.title,
            "authors": [
                author if isinstance(author, str) else getattr(author, "name", str(author))
                for author in node.paper.authors
            ],
            "year": node.paper.year,
            "citation_count": node.paper.citation_count,
            "influential_citation_count": node.paper.influential_citation_count,
            "external_ids": node.paper.external_ids,
            "depth": node.depth,
            "relevance_score": round(node.relevance_score, 4),
            "is_foundation": node.is_foundation,
        }
        
        if include_abstracts and node.paper.abstract:
            node_data["abstract"] = node.paper.abstract
            
        detailed_nodes.append(node_data)
    
    # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
    detailed_nodes.sort(key=lambda n: (-n["relevance_score"], n["depth"]))
    
    # ìµœì¢… ì¶œë ¥ ë°ì´í„° êµ¬ì„±
    output_data: Dict[str, Any] = {
        "version": "1.0.0",
        "generated_at": datetime.now().isoformat(),
        "summary": {
            "total_nodes": len(graph.nodes),
            "total_edges": len(graph.edges),
            "max_depth": max((n.depth for n in graph.nodes.values()), default=0),
            "foundation_candidates": len(graph.get_foundation_candidates()),
        },
        "nodes": detailed_nodes,
        "edges": [
            {
                "source": edge.source_id,
                "target": edge.target_id,
                "type": edge.edge_type,
            }
            for edge in graph.edges
        ],
    }
    
    # ì‚¬ìš©ìž ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if metadata:
        output_data["metadata"] = metadata
    
    # JSON íŒŒì¼ ì €ìž¥
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=indent)
    
    logger.info(f"JSON ë¦¬í¬íŠ¸ ì €ìž¥ ì™„ë£Œ: {output_path} ({len(graph.nodes)}ê°œ ë…¸ë“œ)")
    
    return output_path


# =============================================================================
# Markdown ë¦¬í¬íŠ¸ ìƒì„±
# =============================================================================


def _format_authors(authors: Sequence[Any], max_authors: int = 3) -> str:
    """ì €ìž ëª©ë¡ì„ ë¬¸ìžì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        authors: ì €ìž ëª©ë¡ (ë¬¸ìžì—´ ë˜ëŠ” name ì†ì„±ì„ ê°€ì§„ ê°ì²´).
        max_authors: í‘œì‹œí•  ìµœëŒ€ ì €ìž ìˆ˜.
    
    Returns:
        í¬ë§·ëœ ì €ìž ë¬¸ìžì—´.
    """
    if not authors:
        return "Unknown"
    
    author_names: List[str] = []
    for author in authors[:max_authors]:
        if isinstance(author, str):
            author_names.append(author)
        elif hasattr(author, "name"):
            author_names.append(author.name)
        else:
            author_names.append(str(author))
    
    result = ", ".join(author_names)
    if len(authors) > max_authors:
        result += f" et al. (+{len(authors) - max_authors}ëª…)"
    
    return result


def _format_external_link(canonical_id: str, external_ids: Dict[str, str]) -> str:
    """ì™¸ë¶€ ë§í¬ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        canonical_id: ì •ê·œ ID.
        external_ids: ì™¸ë¶€ ID ë”•ì…”ë„ˆë¦¬.
    
    Returns:
        Markdown ë§í¬ ë¬¸ìžì—´.
    """
    # DOI ë§í¬
    doi = external_ids.get("DOI") or external_ids.get("doi")
    if doi:
        return f"[DOI](https://doi.org/{doi})"
    
    # arXiv ë§í¬
    arxiv = external_ids.get("ArXiv") or external_ids.get("arxiv")
    if arxiv:
        return f"[arXiv](https://arxiv.org/abs/{arxiv})"
    
    # Semantic Scholar ë§í¬
    paper_id = external_ids.get("CorpusId") or external_ids.get("corpus_id")
    if paper_id:
        return f"[S2](https://www.semanticscholar.org/paper/{paper_id})"
    
    # canonical_idì—ì„œ ì¶”ì¶œ ì‹œë„
    if canonical_id.startswith("doi:"):
        return f"[DOI](https://doi.org/{canonical_id[4:]})"
    elif canonical_id.startswith("arxiv:"):
        return f"[arXiv](https://arxiv.org/abs/{canonical_id[6:]})"
    elif canonical_id.startswith("corpus_id:"):
        return f"[S2](https://www.semanticscholar.org/paper/{canonical_id[10:]})"
    
    return ""


def _generate_timeline_section(
    nodes: Sequence[CitationNodeLike],
) -> str:
    """ì—°ë„ë³„ íƒ€ìž„ë¼ì¸ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ëª©ë¡.
    
    Returns:
        Markdown í˜•ì‹ì˜ íƒ€ìž„ë¼ì¸ ì„¹ì…˜.
    """
    # ì—°ë„ë³„ ê·¸ë£¹í™”
    by_year: Dict[int, List[CitationNodeLike]] = defaultdict(list)
    unknown_year: List[CitationNodeLike] = []
    
    for node in nodes:
        year = node.paper.year
        if year is not None:
            by_year[year].append(node)
        else:
            unknown_year.append(node)
    
    if not by_year and not unknown_year:
        return "íƒ€ìž„ë¼ì¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    lines: List[str] = []
    
    # ì—°ë„ìˆœ ì •ë ¬ (ì˜¤ëž˜ëœ ê²ƒë¶€í„°)
    for year in sorted(by_year.keys()):
        year_nodes = sorted(by_year[year], key=lambda n: -n.relevance_score)
        lines.append(f"\n### {year}ë…„\n")
        
        for node in year_nodes[:5]:  # ì—°ë„ë‹¹ ìµœëŒ€ 5ê°œ
            link = _format_external_link(node.canonical_id, node.paper.external_ids)
            foundation_badge = " ðŸ›ï¸" if node.is_foundation else ""
            score = f"[{node.relevance_score:.2f}]"
            
            lines.append(
                f"- **{node.paper.title}**{foundation_badge} {score}\n"
                f"  - {_format_authors(node.paper.authors)} | "
                f"ì¸ìš©: {node.paper.citation_count:,} {link}\n"
            )
        
        if len(year_nodes) > 5:
            lines.append(f"  - ... +{len(year_nodes) - 5}ê°œ ë…¼ë¬¸\n")
    
    # ì—°ë„ ë¯¸ìƒ
    if unknown_year:
        lines.append("\n### ì—°ë„ ë¯¸ìƒ\n")
        for node in unknown_year[:3]:
            lines.append(f"- {node.paper.title}\n")
    
    return "".join(lines)


def _generate_contributions_section(
    nodes: Sequence[CitationNodeLike],
    top_k: int = 10,
) -> str:
    """ì£¼ìš” ê¸°ì—¬ ë…¼ë¬¸ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ëª©ë¡.
        top_k: í‘œì‹œí•  ìƒìœ„ ë…¼ë¬¸ ìˆ˜.
    
    Returns:
        Markdown í˜•ì‹ì˜ ì£¼ìš” ê¸°ì—¬ ì„¹ì…˜.
    """
    # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ ë…¼ë¬¸
    sorted_nodes = sorted(nodes, key=lambda n: -n.relevance_score)[:top_k]
    
    if not sorted_nodes:
        return "ì£¼ìš” ê¸°ì—¬ ë…¼ë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    lines: List[str] = []
    
    for i, node in enumerate(sorted_nodes, 1):
        paper = node.paper
        link = _format_external_link(node.canonical_id, paper.external_ids)
        foundation_badge = " ðŸ›ï¸" if node.is_foundation else ""
        
        lines.append(f"\n#### {i}. {paper.title}{foundation_badge}\n")
        lines.append(f"- **ì €ìž**: {_format_authors(paper.authors)}\n")
        lines.append(f"- **ì—°ë„**: {paper.year or 'N/A'}\n")
        lines.append(f"- **ì¸ìš© ìˆ˜**: {paper.citation_count:,}")
        
        if paper.influential_citation_count > 0:
            lines.append(f" (ì˜í–¥ë ¥ ìžˆëŠ” ì¸ìš©: {paper.influential_citation_count:,})")
        
        lines.append(f"\n- **ê´€ë ¨ì„± ì ìˆ˜**: {node.relevance_score:.4f}\n")
        lines.append(f"- **íƒìƒ‰ ê¹Šì´**: {node.depth}\n")
        
        if link:
            lines.append(f"- **ë§í¬**: {link}\n")
        
        # ì´ˆë¡ (ìžˆëŠ” ê²½ìš°, ì²˜ìŒ 200ìž)
        if paper.abstract:
            abstract_preview = paper.abstract[:200]
            if len(paper.abstract) > 200:
                abstract_preview += "..."
            lines.append(f"\n  > {abstract_preview}\n")
    
    return "".join(lines)


def _generate_foundation_section(
    graph: CitationGraphLike,
    min_depth: int = 2,
) -> str:
    """Foundation candidate ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        graph: ì¸ìš© ê·¸ëž˜í”„.
        min_depth: ìµœì†Œ ê¹Šì´ ê¸°ì¤€.
    
    Returns:
        Markdown í˜•ì‹ì˜ Foundation ì„¹ì…˜.
    """
    candidates = graph.get_foundation_candidates(min_depth=min_depth)
    
    if not candidates:
        return (
            "í˜„ìž¬ íƒìƒ‰ ê¹Šì´ì—ì„œ Foundation candidateê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "`max_depth`ë¥¼ ëŠ˜ë ¤ ë” ê¹Šì€ ê³„ë³´ë¥¼ íƒìƒ‰í•´ ë³´ì„¸ìš”.\n"
        )
    
    lines: List[str] = [
        f"ì´ **{len(candidates)}ê°œ**ì˜ Foundation candidateë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n\n"
    ]
    
    # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
    for i, node in enumerate(candidates[:10], 1):
        paper = node.paper
        link = _format_external_link(node.canonical_id, paper.external_ids)
        
        lines.append(
            f"{i}. **{paper.title}** ({paper.year or 'N/A'})\n"
            f"   - ì €ìž: {_format_authors(paper.authors, max_authors=2)}\n"
            f"   - ì¸ìš© ìˆ˜: {paper.citation_count:,} | ê¹Šì´: {node.depth} | "
            f"ì ìˆ˜: {node.relevance_score:.3f} {link}\n"
        )
    
    if len(candidates) > 10:
        lines.append(f"\n... +{len(candidates) - 10}ê°œ ì¶”ê°€ Foundation candidates\n")
    
    return "".join(lines)


def _generate_citation_paths_section(
    graph: CitationGraphLike,
    max_paths: int = 5,
) -> str:
    """ì¸ìš© ê²½ë¡œ ì‹œê°í™” ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        graph: ì¸ìš© ê·¸ëž˜í”„.
        max_paths: í‘œì‹œí•  ìµœëŒ€ ê²½ë¡œ ìˆ˜.
    
    Returns:
        Markdown í˜•ì‹ì˜ ê²½ë¡œ ì‹œê°í™” ì„¹ì…˜.
    """
    if not graph.edges:
        return "ì¸ìš© ê²½ë¡œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    # ê¹Šì´ë³„ ë…¸ë“œ ê·¸ë£¹í™”
    by_depth: Dict[int, List[CitationNodeLike]] = defaultdict(list)
    for node in graph.nodes.values():
        by_depth[node.depth].append(node)
    
    if not by_depth:
        return "ê²½ë¡œ ì‹œê°í™”ë¥¼ ìœ„í•œ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    lines: List[str] = []
    
    # íŠ¸ë¦¬ êµ¬ì¡° ì‹œê°í™” (Mermaid ë‹¤ì´ì–´ê·¸ëž¨)
    lines.append("```mermaid\ngraph TD\n")
    
    # ìƒ˜í”Œ ê²½ë¡œ ì¶”ì¶œ (ìƒìœ„ ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€)
    path_count = 0
    displayed_nodes: set[str] = set()
    
    for edge in graph.edges:
        if path_count >= max_paths * 3:  # ê²½ë¡œë‹¹ í‰ê·  3ê°œ ì—£ì§€ ê°€ì •
            break
        
        source = graph.nodes.get(edge.source_id)
        target = graph.nodes.get(edge.target_id)
        
        if source and target:
            # ë…¸ë“œ ID ì •ë¦¬ (Mermaid í˜¸í™˜)
            source_id = source.canonical_id.replace(":", "_").replace(".", "_")[:20]
            target_id = target.canonical_id.replace(":", "_").replace(".", "_")[:20]
            
            # ë…¸ë“œ ë¼ë²¨ (ì§§ì€ ì œëª©)
            source_label = source.paper.title[:30].replace('"', "'")
            target_label = target.paper.title[:30].replace('"', "'")
            
            if source.canonical_id not in displayed_nodes:
                lines.append(f'    {source_id}["{source_label}..."]\n')
                displayed_nodes.add(source.canonical_id)
            
            if target.canonical_id not in displayed_nodes:
                lines.append(f'    {target_id}["{target_label}..."]\n')
                displayed_nodes.add(target.canonical_id)
            
            arrow = "-->" if edge.edge_type == "cites" else "-.->|cited by|"
            lines.append(f"    {source_id} {arrow} {target_id}\n")
            path_count += 1
    
    lines.append("```\n")
    
    # í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²½ë¡œ ìš”ì•½
    lines.append("\n**ì£¼ìš” ì¸ìš© ì²´ì¸:**\n\n")
    
    # ê¹Šì´ë³„ ëŒ€í‘œ ë…¼ë¬¸ìœ¼ë¡œ ê²½ë¡œ êµ¬ì„±
    max_depth = max(by_depth.keys()) if by_depth else 0
    
    for depth in range(min(max_depth + 1, 4)):  # ìµœëŒ€ ê¹Šì´ 4ê¹Œì§€
        if depth in by_depth:
            top_node = max(by_depth[depth], key=lambda n: n.relevance_score)
            prefix = "  " * depth
            arrow = "â””â”€" if depth > 0 else "â—"
            year_str = f"({top_node.paper.year})" if top_node.paper.year else ""
            
            lines.append(
                f"{prefix}{arrow} **{top_node.paper.title[:50]}...** {year_str}\n"
            )
    
    return "".join(lines)


def generate_markdown_report(
    graph: CitationGraphLike,
    seed_info: Dict[str, Any],
    output_path: Union[str, Path],
    *,
    include_mermaid: bool = True,
    top_contributions: int = 10,
    foundation_min_depth: int = 2,
) -> Path:
    """ì¸ìš© ê·¸ëž˜í”„ë¥¼ Markdown ë¦¬í¬íŠ¸ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
    ì‚¬ëžŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ì˜ Lineage ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    íƒ€ìž„ë¼ì¸, ì£¼ìš” ê¸°ì—¬, Foundation candidates, ì¸ìš© ê²½ë¡œ ì‹œê°í™”ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    
    Args:
        graph: ë¶„ì„ëœ ì¸ìš© ê·¸ëž˜í”„ ê°ì²´.
        seed_info: ì‹œë“œ ë…¼ë¬¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬. í•„ìˆ˜ í‚¤:
            - title: ë…¼ë¬¸ ì œëª©
            - authors: ì €ìž ëª©ë¡
            - year: ì¶œíŒ ì—°ë„
            ì„ íƒ í‚¤:
            - abstract: ì´ˆë¡
            - canonical_id: ì •ê·œ ID
            - external_ids: ì™¸ë¶€ ID ë”•ì…”ë„ˆë¦¬
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ.
        include_mermaid: Mermaid ë‹¤ì´ì–´ê·¸ëž¨ í¬í•¨ ì—¬ë¶€ (ê¸°ë³¸ê°’: True).
        top_contributions: ì£¼ìš” ê¸°ì—¬ ì„¹ì…˜ì— í‘œì‹œí•  ë…¼ë¬¸ ìˆ˜ (ê¸°ë³¸ê°’: 10).
        foundation_min_depth: Foundation candidate ìµœì†Œ ê¹Šì´ (ê¸°ë³¸ê°’: 2).
    
    Returns:
        ì €ìž¥ëœ íŒŒì¼ì˜ Path ê°ì²´.
    
    Raises:
        OSError: íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨ ì‹œ.
        KeyError: seed_infoì— í•„ìˆ˜ í‚¤ê°€ ì—†ì„ ë•Œ.
    
    Example:
        >>> seed_info = {
        ...     "title": "Attention Is All You Need",
        ...     "authors": ["Vaswani et al."],
        ...     "year": 2017,
        ... }
        >>> path = generate_markdown_report(graph, seed_info, "lineage.md")
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    nodes = list(graph.nodes.values())
    
    # ì‹œë“œ ì •ë³´ ì¶”ì¶œ
    seed_title = seed_info.get("title", "Unknown Paper")
    seed_authors = seed_info.get("authors", [])
    seed_year = seed_info.get("year")
    seed_abstract = seed_info.get("abstract", "")
    seed_external_ids = seed_info.get("external_ids", {})
    seed_canonical_id = seed_info.get("canonical_id", "")
    
    # í†µê³„ ê³„ì‚°
    years = [n.paper.year for n in nodes if n.paper.year is not None]
    min_year = min(years) if years else None
    max_year = max(years) if years else None
    total_citations = sum(n.paper.citation_count for n in nodes)
    avg_relevance = sum(n.relevance_score for n in nodes) / len(nodes) if nodes else 0
    
    # ë¦¬í¬íŠ¸ êµ¬ì„±
    report_lines: List[str] = []
    
    # í—¤ë”
    report_lines.append(f"# Citation Lineage Report: {seed_title}\n\n")
    report_lines.append(f"**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    # ì‹œë“œ ë…¼ë¬¸ ì •ë³´
    report_lines.append("## ðŸ“„ ì‹œë“œ ë…¼ë¬¸ ì •ë³´\n\n")
    report_lines.append(f"- **ì œëª©**: {seed_title}\n")
    report_lines.append(f"- **ì €ìž**: {_format_authors(seed_authors)}\n")
    report_lines.append(f"- **ì¶œíŒì—°ë„**: {seed_year or 'N/A'}\n")
    
    seed_link = _format_external_link(seed_canonical_id, seed_external_ids)
    if seed_link:
        report_lines.append(f"- **ë§í¬**: {seed_link}\n")
    
    if seed_abstract:
        report_lines.append(f"\n> {seed_abstract[:300]}{'...' if len(seed_abstract) > 300 else ''}\n")
    
    report_lines.append("\n---\n\n")
    
    # ìš”ì•½ í†µê³„
    report_lines.append("## ðŸ“Š ë¶„ì„ ìš”ì•½\n\n")
    report_lines.append("| í•­ëª© | ê°’ |\n")
    report_lines.append("|------|----|\n")
    report_lines.append(f"| ì´ ë…¼ë¬¸ ìˆ˜ | {len(nodes):,} |\n")
    report_lines.append(f"| ì´ ì¸ìš© ê´€ê³„ | {len(graph.edges):,} |\n")
    report_lines.append(f"| ìµœëŒ€ íƒìƒ‰ ê¹Šì´ | {max((n.depth for n in nodes), default=0)} |\n")
    report_lines.append(f"| Foundation Candidates | {len(graph.get_foundation_candidates(foundation_min_depth))} |\n")
    report_lines.append(f"| ì—°ë„ ë²”ìœ„ | {min_year or 'N/A'} ~ {max_year or 'N/A'} |\n")
    report_lines.append(f"| ì´ ì¸ìš© ìˆ˜ í•©ê³„ | {total_citations:,} |\n")
    report_lines.append(f"| í‰ê·  ê´€ë ¨ì„± ì ìˆ˜ | {avg_relevance:.4f} |\n")
    report_lines.append("\n---\n\n")
    
    # íƒ€ìž„ë¼ì¸ ì„¹ì…˜
    report_lines.append("## ðŸ“… íƒ€ìž„ë¼ì¸ (ì—°ë„ë³„ ë…¼ë¬¸)\n")
    report_lines.append(_generate_timeline_section(nodes))
    report_lines.append("\n---\n\n")
    
    # ì£¼ìš” ê¸°ì—¬ ì„¹ì…˜
    report_lines.append("## ðŸ† ì£¼ìš” ê¸°ì—¬ ë…¼ë¬¸\n")
    report_lines.append(
        f"ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ {top_contributions}ê°œ ë…¼ë¬¸ìž…ë‹ˆë‹¤.\n"
    )
    report_lines.append(_generate_contributions_section(nodes, top_k=top_contributions))
    report_lines.append("\n---\n\n")
    
    # Foundation Candidates ì„¹ì…˜
    report_lines.append("## ðŸ›ï¸ Foundation Candidates\n\n")
    report_lines.append(
        "Foundation candidateëŠ” í˜„ìž¬ ì—°êµ¬ì˜ ê·¼ë³¸ì ì¸ ê¸°ë°˜ì´ ë˜ëŠ” ë…¼ë¬¸ìž…ë‹ˆë‹¤.\n"
        f"ê¹Šì´ {foundation_min_depth} ì´ìƒì—ì„œ ë°œê²¬ëœ ì˜í–¥ë ¥ ìžˆëŠ” ë…¼ë¬¸ë“¤ìž…ë‹ˆë‹¤.\n\n"
    )
    report_lines.append(_generate_foundation_section(graph, min_depth=foundation_min_depth))
    report_lines.append("\n---\n\n")
    
    # ì¸ìš© ê²½ë¡œ ì‹œê°í™” ì„¹ì…˜
    report_lines.append("## ðŸ”— ì¸ìš© ê²½ë¡œ ì‹œê°í™”\n\n")
    if include_mermaid:
        report_lines.append(_generate_citation_paths_section(graph))
    else:
        report_lines.append("(Mermaid ë‹¤ì´ì–´ê·¸ëž¨ ë¹„í™œì„±í™”ë¨)\n")
    
    report_lines.append("\n---\n\n")
    
    # í‘¸í„°
    report_lines.append("## ðŸ“ ë…¸íŠ¸\n\n")
    report_lines.append("- ðŸ›ï¸ ì•„ì´ì½˜ì€ Foundation candidateë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n")
    report_lines.append("- ê´€ë ¨ì„± ì ìˆ˜ëŠ” ì˜ë¯¸ì  ìœ ì‚¬ë„, ì¸ìš© ì˜í–¥ë ¥, ê¸°ì´ˆ ê°€ì¤‘ì¹˜ì˜ ì¡°í•©ìž…ë‹ˆë‹¤.\n")
    report_lines.append("- ì´ ë¦¬í¬íŠ¸ëŠ” Citation Tracer v1.0.0ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
    
    # íŒŒì¼ ì €ìž¥
    report_content = "".join(report_lines)
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    logger.info(
        f"Markdown ë¦¬í¬íŠ¸ ì €ìž¥ ì™„ë£Œ: {output_path} "
        f"({len(nodes)}ê°œ ë…¸ë“œ, {len(report_content):,} ë°”ì´íŠ¸)"
    )
    
    return output_path


# =============================================================================
# íŽ¸ì˜ í•¨ìˆ˜
# =============================================================================


def generate_reports(
    graph: CitationGraphLike,
    seed_info: Dict[str, Any],
    output_dir: Union[str, Path],
    base_name: str = "lineage",
) -> Dict[str, Path]:
    """JSONê³¼ Markdown ë¦¬í¬íŠ¸ë¥¼ ë™ì‹œì— ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        graph: ë¶„ì„ëœ ì¸ìš© ê·¸ëž˜í”„.
        seed_info: ì‹œë“œ ë…¼ë¬¸ ì •ë³´.
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬.
        base_name: ê¸°ë³¸ íŒŒì¼ëª… (í™•ìž¥ìž ì œì™¸).
    
    Returns:
        ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬ {"json": Path, "markdown": Path}.
    
    Example:
        >>> paths = generate_reports(graph, seed_info, "results/")
        >>> print(f"JSON: {paths['json']}")
        >>> print(f"Markdown: {paths['markdown']}")
    """
    output_dir = Path(output_dir)
    
    json_path = generate_json_report(
        graph,
        output_dir / f"{base_name}.json",
        metadata={"seed": seed_info},
    )
    
    md_path = generate_markdown_report(
        graph,
        seed_info,
        output_dir / f"{base_name}.md",
    )
    
    return {
        "json": json_path,
        "markdown": md_path,
    }
